# PTO-WSP v9: NPU Backend Support (Ascend) — Implementation Notes

This document defines the **v9 deliverable** for Ascend NPU backend support and
how it integrates with PTO-WSP’s codegen-first model.

**Reference baseline:** `references/pto-isa-wc/` (device runtime + host/aicpu/aicore
codegen patterns). See `docs/reference/14_pto_isa_wc.md`.

**PTO-WSP constraints (keep our features):**
- Preserve v9 scheduling semantics that are required for programmability:
  - **preserve/enforce:** `dispatch` + `task_window` (stall-only)
  - **explicitly unsupported (v9):** other schedule knobs (streams/stream_by/timing/ready policies/...)
- Support **on-device task expansion on AICPU** (device-side expansion from a compact plan).
- Use **pto-isa** to generate **AICore** kernel code (tile ops / MMA / vector).
- Support **dynamic axes** without requiring a full recompile of the whole program artifact.

---

## 1. v9 NPU Deliverables (What “done” means)

### 1.1 Build artifacts
- **Host artifact**: a shared library or executable host runner that:
  - allocates/copies tensors to device,
  - launches AICPU scheduler kernels,
  - launches AICore worker kernels,
  - synchronizes and copies results back.
- **AICPU artifact**: device-side scheduler code that:
  - receives a compact plan + runtime parameters,
  - expands tasks on-device (dynamic axes, ragged/sparse),
  - dispatches tasks to AICore workers and tracks completion.
- **AICore artifact**: device-side kernel dispatch + per-kernel entrypoints:
  - `switch(kernel_id)` dispatch (pto-isa-wc pattern),
  - kernels generated by PTO-ISA (or wrappers around PTO-ISA intrinsics).

### 1.2 Execution semantics
- Correctness: results match CPU reference for representative examples.
- Timing: cycles/timestamps are available without a parallel PTO‑RT cost model:
  - CPU-sim uses **PTO‑ISA-provided cycle reporting/instrumentation** for kernels (workload orchestration may still model dispatch/channel overhead),
  - NPU uses **device timestamp deltas / HW counters** (or PTO‑ISA kernel reports if exposed) and propagates them to host.

---

## 2. Architecture Overview (pto-isa-wc inspired)

pto-isa-wc provides an end-to-end structure that we reuse conceptually:
- `runtime/host/*` device runner + memory allocator
- `runtime/aicpu/*` multithreaded scheduler / graph executor
- `runtime/aicore/*` kernel dispatcher
- `runtime/graph/*` shared task graph structures + handshake protocol

In PTO-WSP v9 we keep PTO-WSP’s schedule features and shift *where* tasks are
expanded:

### 2.1 Host vs AICPU responsibilities
- **Host**:
  - uploads tensors and a compact plan,
  - uploads per-run dynamic values (axis sizes, ragged indices, constants),
  - launches device components and handles I/O.
- **AICPU**:
  - expands the compact plan into concrete tasks using runtime values,
  - performs ready-queue management + dependency fanin updates,
  - dispatches ready tasks to AICore workers via handshake/shared queues.
- **AICore**:
  - executes kernels and signals completion back to AICPU.

This matches PTO-WSP’s “on-device task gen” direction; see `docs/design/on-device-task-gen.md`.

---

## 3. Data/ABI Contracts

### 3.1 Compact plan format (host → device)
The host uploads a compact, immutable “plan” describing:
- kernels (IDs + metadata needed for dispatch),
- a DAG template and/or schedule operators,
- loop/selection constructs that reference **dynamic symbols** (axis sizes, ragged lists).

The AICPU expands this plan at runtime into a task stream.

### 3.2 Dynamic symbols (runtime → device, and runtime → CPU-sim codegen)
Dynamic values must be provided **without recompiling the whole artifact**.

Recommended contract:
- Each compiled artifact exports a **symbol table**:
  - `symbol_id`, `name_hash`, `kind` (axis_size, scalar, ragged_indptr, ragged_indices, sparse_*),
  - expected dtype/width and shape constraints (if applicable).
- The runtime provides per-run values in a **packed buffer**:
  - scalars: `u64/f64` slots
  - arrays: device pointers for ragged/sparse index structures
  - axis sizes: `u64` slots (often derived from input tensor shapes)

This enables:
- CPU-sim codegen: emitted loops query `get_symbol_u64(symbol_id)` and index buffers.
- NPU: AICPU reads the same packed buffer from device memory.

### 3.3 Avoiding “full artifact” recompiles
There are two complementary strategies:

**A) Generic code with runtime bounds (preferred for v9)**
- Workload loops use runtime axis sizes; kernels use fixed tile shapes but accept
  runtime “tail sizes”/masks via task args or symbol buffer.
- No recompilation when only batch/seq/token counts change.

**B) Fatbin / multi-variant kernels (when specialization matters)**
- Compile multiple kernel variants into the same artifact (or a separate kernel
  library) and dispatch based on runtime values (e.g. alignment, head_dim).
- If a new variant is needed, compile **only the missing kernel** and register
  it (no workload recompile). Workload calls `get_kernel(kernel_id, variant_id)`.

---

## 4. Codegen Pipeline (host/aicpu/aicore)

### 4.1 Kernel codegen (AICore)
- Input: traced `KernelIR` (`@kernel` + `pto.*` ops).
- Output:
  - AICore kernel sources via PTO-ISA codegen,
  - a dispatcher `kernel.cpp` that maps `kernel_id → kernel_fn`.

### 4.2 Workload/schedule codegen (AICPU)
- Input: workload tree + schedule configuration.
- Output:
  - a compact plan + metadata (symbol table, kernel table),
  - AICPU scheduler code that expands/dispatches tasks.

### 4.3 Host packaging
- Bundle:
  - host runner,
  - device binaries (AICPU + AICore),
  - metadata for symbol binding.

---

## 5. Testing expectations

### 5.1 CPU-sim (mandatory for every PR touching codegen)
- All `examples/*` must validate correctness and print a cycle estimate.
- Prefer direct example execution (examples are self-validating) and `python -m pytest -q` for regression coverage.

### 5.2 NPU (v9 milestone)
- Add at least one end-to-end NPU validation that:
  - builds host/aicpu/aicore artifacts,
  - runs on-device task expansion on AICPU,
  - uses PTO-ISA-generated kernels on AICore,
  - checks numerical correctness against a CPU reference.

---

## 6. Concrete Implementation References (pto-isa-wc)

The following files in `references/pto-isa-wc/` provide the most actionable
implementation patterns for PTO-WSP’s v9 Ascend backend.

### 6.1 Device-side synchronization (AICPU ↔ AICore)
- Handshake ABI (per-core, cacheline aligned): `references/pto-isa-wc/runtime/graph/handshake.h`
  - Fields: `aicpu_ready`, `aicore_done`, `task`, `task_status`, `control`.
  - Protocol: AICPU sets ready → AICore acks → AICPU assigns `task` + sets busy →
    AICore executes and clears busy → AICPU releases deps and clears `task`.
- Cache coherency polling on AICore: `references/pto-isa-wc/runtime/aicore/kernel.cpp`
  - Uses `dcci(my_hank, ENTIRE_DATA_CACHE, CACHELINE_OUT)` in poll loops.

### 6.2 CANN runtime ABI constraints (kernel args layout)
- CANN-facing argument layout with padding/offset constraints:
  `references/pto-isa-wc/runtime/graph/kernel_args.h`
  - `KernelArgs.unused[5]` exists to satisfy `libaicpu_extend_kernels.so` offsets.
  - `DeviceArgs` carries topology (`nrAic`, `nrAiv`, `nrValidAic`, `nrAicpu`) and
    AICPU SO location (`aicpuSoBin`, `aicpuSoLen`) plus `scheCpuNum`.

### 6.3 Device-side task graph representation
- Graph + task representation (fixed-size arrays + atomic fanin):
  - `references/pto-isa-wc/runtime/graph/graph.h`
  - `references/pto-isa-wc/runtime/graph/graph.cpp`
  - `Task` includes `func_id`, `args[GRAPH_MAX_ARGS]`, atomic `fanin`, `fanout[]`.

### 6.4 AICPU scheduler loop (device-side execution manager)
- Multi-threaded AICPU scheduler (ready queue + fanin release + dispatch):
  `references/pto-isa-wc/runtime/aicpu/graph_executor.cpp`
  - Core phases:
    - handshake all managed cores (`HankAiCore`)
    - poll for completed tasks, `fanin.fetch_sub()` successors, push newly-ready tasks
    - dispatch ready tasks to idle cores by writing `h->task` and setting `h->task_status = 1`
    - shutdown by setting `h->control = 1`
  - Example topology mapping: “1 AIC + 2 AIV per thread” (hardcoded in this reference).

### 6.5 AICore kernel dispatch pattern
- AICore worker control loop + `switch(func_id)` dispatch:
  `references/pto-isa-wc/runtime/aicore/kernel.cpp`
  - Typical argument handling:
    - `reinterpret_cast<__gm__ T*>(task->args[i])` for pointers
    - `union { uint64_t u64; float f32; }` to pass scalars through `uint64_t args[]`
  - AIC/AIV dual entry naming: `KERNEL_ENTRY(x)` macro pattern.

### 6.6 Host packaging and kernel launches
- Host runner that allocates/copies graph + handshake buffers + tensors, then launches:
  - AICPU init kernel by name (`DynTileFwkBackendKernelServerInit`)
  - AICPU main kernel by name (`DynTileFwkBackendKernelServer`)
  - AICore worker kernel via ELF registration and launch
  - Files:
    - `references/pto-isa-wc/runtime/host/devicerunner.h`
    - `references/pto-isa-wc/runtime/host/devicerunner.cpp`
    - `references/pto-isa-wc/runtime/host/memoryallocator.h`
    - `references/pto-isa-wc/runtime/host/memoryallocator.cpp`
  - Launch APIs used:
    - `rtAicpuKernelLaunchExWithArgs(...)`
    - `rtRegisterAllKernel(...)` + `rtKernelLaunchWithHandleV2(...)`

### 6.7 Python binding shape (optional reference for PTO-WSP tests/tools)
- Minimal pybind wrapper for Graph + DeviceRunner:
  - `references/pto-isa-wc/runtime/python/bindings.cpp`
  - `references/pto-isa-wc/runtime/python/graphbuilder.py`

### 6.8 Dynamic tiling / tail strategy (useful for PTO-WSP dynamic axes)
- Reference implementation of “full tiles + tail tile” control flow:
  `references/pto-isa-wc/pto_dynamic_tiling.py`
  - Uses scalars like `num_full_tiles`, `tail_elements`, `has_tail` to avoid
    recompilation when only tensor sizes change.
  - This maps naturally to PTO-WSP’s “symbol table + runtime binding” design:
    axis sizes become symbols, tail handling uses runtime-provided counts/masks.

### 6.9 Generated Ascend kernel style (AscendC operator code)
- Example of generated AscendC kernel structure (queues/pipeline/DataCopy/Matmul):
  `references/pto-isa-wc/examples/output_ascend910b/**`
  - Example file: `references/pto-isa-wc/examples/output_ascend910b/torch_tensor/tensor_mm.cpp`
  - Use this to validate the shape of PTO-ISA-generated AICore kernels and
    decide how PTO-WSP wraps/dispatches them.
